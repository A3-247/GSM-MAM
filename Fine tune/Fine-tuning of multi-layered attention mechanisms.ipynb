{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaa function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCrossEntropyLossWithL21Regularization(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='mean', lambda_l21=0.001):\n",
    "        super(CustomCrossEntropyLossWithL21Regularization, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.lambda_l21 = lambda_l21\n",
    "\n",
    "    def l2_1_regularization(self, model):\n",
    "        reg_loss = 0\n",
    "        for param in model.parameters():\n",
    "            if param.dim() > 1:\n",
    "                reg_loss += torch.sum(torch.sqrt(torch.sum(param**2, dim=1))) \n",
    "        return reg_loss\n",
    "\n",
    "    def forward(self, input, target, model=None):\n",
    "\n",
    "        loss = F.cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
    "\n",
    "        if model is not None:\n",
    "            l2_1_loss = self.l2_1_regularization(model)\n",
    "            loss += self.lambda_l21 * l2_1_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e606eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part1 ：Att_net\n",
    "from math import sqrt\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "class Att_brainnet(nn.Module):\n",
    "    def __init__(self, models, device='cpu'):\n",
    "        super(Att_brainnet, self).__init__()\n",
    "        \n",
    "        self.models = models \n",
    "        \n",
    " \n",
    "    def forward(self):\n",
    "        # x: batch, n, dim_q\n",
    "        X_newRA_IA = torch.tensor(X_newRA_I, dtype=torch.float64)\n",
    "        X_newEA_IA = torch.tensor(X_newEA_I, dtype=torch.float64)\n",
    "        \n",
    "        for lll, model in enumerate(self.models):\n",
    "            Feature=torch.zeros((NUM_R[lll],161),dtype=torch.float64)\n",
    "            for i in range(161):\n",
    "                for j in range(NUM_R[lll]):\n",
    "                    Feature[j][i] = to_tensor(X_bian_R[lll][j][i])\n",
    "            YQ = model(Feature)\n",
    "            tagAA=torch.sum(YQ,dim=1).detach().reshape(-1, 1)        \n",
    "\n",
    "            mean = tagAA.mean(dim=0, keepdim=True)\n",
    "            std = tagAA.std(dim=0, keepdim=True)\n",
    "\n",
    "            tagAAG = (tagAA - mean) / (std + 1e-6)\n",
    "\n",
    "            tagAAG=tagAAG.reshape(-1, 1)\n",
    "            for j in range(NUM_R[lll]):\n",
    "                SS1 = np.array(ROI_record[lll][j],dtype='int')\n",
    "                SS2 = np.array(list_BEST[SS1].pos_ac,dtype='int')\n",
    "                X_newRA_IA[:, SS2] = X_newRA_IA[:, SS2] + (X_newR_tensor[:, SS2] * (tagAAG[j] / NA_tensor[SS1]))\n",
    "                X_newEA_IA[:, SS2] = X_newEA_IA[:, SS2] + (X_newE_tensor[:, SS2] * (tagAAG[j] / NA_tensor[SS1]))\n",
    "            lll=lll+1\n",
    "        \n",
    "        return X_newRA_IA,X_newEA_IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SelfAttention(161, NUM_R[i], NUM_R[i], device='cpu') for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a985a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lll,model in enumerate(models):\n",
    "    save_model = torch.load(\"./SA_FINAL_\"+str(op_now)+\"_\"+str(iii)+\"_\"+str(lll)+\".pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(f\"Model {lll+1} loaded with weights from {save_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model = Att_brainnet(models=models, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5024b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [model.parameters() for model in models]\n",
    "all_params = [param for sublist in params for param in sublist]\n",
    "optimizer = torch.optim.Adam(all_params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a35cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tensor=torch.from_numpy(Y_train)\n",
    "Y_train_tensor=Y_train_tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 \n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    att_model.train()\n",
    "        \n",
    "    outputR,outputE = att_model()\n",
    "\n",
    "    loss = criterion(outputR,Y_train_tensor)\n",
    "    \n",
    "    print(outputR,outputE)\n",
    "        \n",
    "    X_trainA=outputR.detach().numpy()\n",
    "    Y_trainA=Y_train\n",
    "    X_testA=outputE.detach().numpy()\n",
    "    Y_testA=Y_test\n",
    "    print(X_trainA.shape)\n",
    "    print(X_testA.shape)\n",
    "    clf_linear = svm.SVC(kernel='linear',C=0.095)\n",
    "    clf_linear.fit(X_trainA,Y_trainA)\n",
    "    score_linear_test = clf_linear.score(X_testA,Y_testA)\n",
    "    score_linear_train = clf_linear.score(X_trainA,Y_trainA)\n",
    "    predict_test = clf_linear.predict(X_testA)\n",
    "    print(predict_test,Y_testA)\n",
    "    print(epoch,\"SVM Test  Accuracy : %.4g\" % (score_linear_test))\n",
    "    print(epoch,\"SVM Train  Accuracy : %.4g\" % (score_linear_train))\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Total Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6659d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part1I ：Att_pwn\n",
    "from math import sqrt\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "class Att_connect(nn.Module):\n",
    "    def __init__(self, modelsPT, modelsNT, modelsPE, modelsNE, device='cpu'):\n",
    "        super(Att_connect, self).__init__()\n",
    "        \n",
    "        self.modelsPT = modelsPT\n",
    "        self.modelsNT = modelsNT\n",
    "        \n",
    "        self.modelsPE = modelsPE\n",
    "        self.modelsNE = modelsNE\n",
    "        \n",
    " \n",
    "    def forward(self):\n",
    "        X_newRA_IIA = torch.tensor(X_newRA_II, dtype=torch.float64)\n",
    "        X_newEA_IIA = torch.tensor(X_newEA_II, dtype=torch.float64)\n",
    "        \n",
    "        u=0\n",
    "        for u, model in enumerate(self.modelsPE):\n",
    "            tagAA1=torch.zeros(POS_test[u])\n",
    "            if (POS_test[u]!=0):\n",
    "                Feature1=torch.zeros((POS_test[u],1),dtype=torch.float64)\n",
    "                for j in range(POS_test[u]):\n",
    "                    Feature1[j][0]=to_tensor(X_bian_P_test[j][u])\n",
    "                YQ1=model(Feature1)\n",
    "                tagAA1=torch.sum(YQ1,dim=1)\n",
    "                for j in range(POS_test[u]): \n",
    "                    X_newEA_IIA[u][POS_record_test[u][j]] = X_newEA_IIA[u][POS_record_test[u][j]].clone() * (tagAA1[j])\n",
    "            u=u+1\n",
    "        \n",
    "        for u, model in enumerate(self.modelsNE):\n",
    "            tagAA2=torch.zeros(NEV_test[u])\n",
    "            if (NEV_test[u]!=0):\n",
    "                Feature2=torch.zeros((NEV_test[u],1),dtype=torch.float64)\n",
    "                for j in range(NEV_test[u]):\n",
    "                    Feature2[j][0]=to_tensor(X_bian_N_test[j][u])\n",
    "                YQ2=model(Feature2)\n",
    "                tagAA2=torch.sum(YQ2,dim=1)\n",
    "                for j in range(NEV_test[u]):\n",
    "                    X_newEA_IIA[u][NEV_record_test[u][j]]=X_newEA_IIA[u][NEV_record_test[u][j]].clone()*(tagAA2[j])\n",
    "        \n",
    "        for v, model in enumerate(self.modelsPT):\n",
    "            tagAA1=torch.zeros(POS_train[v])\n",
    "            if (POS_train[v]!=0):\n",
    "                Feature1=torch.zeros((POS_train[v],1),dtype=torch.float64)\n",
    "                for j in range(POS_train[v]):\n",
    "                    Feature1[j][0]=to_tensor(X_bian_P_train[j][v])\n",
    "                YQ1=model(Feature1)\n",
    "                tagAA1=torch.sum(YQ1,dim=1)\n",
    "                for j in range(POS_train[v]): \n",
    "                    X_newRA_IIA[v][POS_record_train[v][j]]=X_newRA_IIA[v][POS_record_train[v][j]].clone()*(tagAA1[j])\n",
    "    \n",
    "        for v, model in enumerate(self.modelsNT):\n",
    "            tagAA2=torch.zeros(NEV_train[v])\n",
    "            if (NEV_train[v]!=0):\n",
    "                Feature2=torch.zeros((NEV_train[v],1),dtype=torch.float64)\n",
    "                for j in range(NEV_train[v]):\n",
    "                    Feature2[j][0]=to_tensor(X_bian_N_train[j][v])\n",
    "                YQ2=model(Feature2)\n",
    "                tagAA2=torch.sum(YQ2,dim=1)\n",
    "                for j in range(NEV_train[v]):\n",
    "                    X_newRA_IIA[v][NEV_record_train[v][j]]=X_newRA_IIA[v][NEV_record_train[v][j]].clone()*(tagAA2[j])\n",
    "    \n",
    "        mean = X_newRA_IIA.mean(dim=0, keepdim=True)\n",
    "        std  = X_newRA_IIA.std(dim=0, keepdim=True)\n",
    "        X_newRA_IIA = (X_newRA_IIA - mean) / (std + 1e-6)\n",
    "            \n",
    "        mean = X_newEA_IIA.mean(dim=0, keepdim=True)\n",
    "        std  = X_newEA_IIA.std(dim=0, keepdim=True)\n",
    "        X_newEA_IIA = (X_newEA_IIA - mean) / (std + 1e-6)\n",
    "            \n",
    "        return X_newRA_IIA,X_newEA_IIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPE = [SelfAttention(1, POS_test[u], POS_test[u], device='cpu') for u in range(23)]\n",
    "modelsNE = [SelfAttention(1, NEV_test[u], NEV_test[u], device='cpu') for u in range(23)]\n",
    "\n",
    "modelsPT = [SelfAttention(1, POS_train[v], POS_train[v], device='cpu') for v in range(138)]\n",
    "modelsNT = [SelfAttention(1, NEV_train[v], NEV_train[v], device='cpu') for v in range(138)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lll,model in enumerate(modelsPE):\n",
    "    print(lll)\n",
    "    save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll*7)+\"_\"+str(op_now)+\"A.pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(f\"Model {lll} loaded with weights from {save_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebee750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lll,model in enumerate(modelsNE):\n",
    "    print(lll)\n",
    "    save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll*7)+\"_\"+str(op_now)+\"B.pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(f\"Model {lll} loaded with weights from {save_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d02004",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLL=0\n",
    "for lll,model in enumerate(modelsPT):\n",
    "    if (lll%6==op_now):\n",
    "        LLL=LLL+1\n",
    "    print(lll,LLL)\n",
    "    save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll+LLL)+\"_\"+str(op_now)+\"A.pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(f\"Model {lll+1} loaded with weights from save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLL=0\n",
    "for lll,model in enumerate(modelsNT):\n",
    "    if (lll%6==op_now):\n",
    "        LLL=LLL+1\n",
    "    print(lll,LLL)\n",
    "    save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll+LLL)+\"_\"+str(op_now)+\"B.pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(f\"Model {lll+1} loaded with weights from save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406edfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnw_model = Att_connect(modelsPE=modelsPE,modelsNE=modelsNE,modelsPT=modelsPT,modelsNT=modelsNT, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e22c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsPE = [model.parameters() for model in modelsPE]\n",
    "paramsNE = [model.parameters() for model in modelsNE]\n",
    "paramsPT = [model.parameters() for model in modelsPT]\n",
    "paramsNT = [model.parameters() for model in modelsNT]\n",
    "\n",
    "all_paramsPE = [param for sublist in paramsPE for param in sublist]\n",
    "all_paramsNE = [param for sublist in paramsNE for param in sublist]\n",
    "all_paramsPT = [param for sublist in paramsPT for param in sublist]\n",
    "all_paramsNT = [param for sublist in paramsNT for param in sublist]\n",
    "\n",
    "optimizerPE = torch.optim.Adam(all_paramsPE, lr=0.0001)\n",
    "optimizerNE = torch.optim.Adam(all_paramsNE, lr=0.0001)\n",
    "optimizerPT = torch.optim.Adam(all_paramsPT, lr=0.0001)\n",
    "optimizerNT = torch.optim.Adam(all_paramsNT, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd18282",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tensor=torch.from_numpy(Y_train)\n",
    "Y_train_tensor=Y_train_tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizerPE.zero_grad() \n",
    "    optimizerNE.zero_grad()\n",
    "    optimizerPT.zero_grad()\n",
    "    optimizerNT.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    pnw_model.train()\n",
    "        \n",
    "    outputR,outputE = pnw_model()\n",
    "        \n",
    "    loss = criterion(outputR,Y_train_tensor)\n",
    "    \n",
    "    print(outputR,outputE)\n",
    "        \n",
    "    X_trainA=outputR.detach().numpy()\n",
    "    Y_trainA=Y_train\n",
    "    X_testA=outputE.detach().numpy()\n",
    "    Y_testA=Y_test\n",
    "    print(X_trainA.shape)\n",
    "    print(X_testA.shape)\n",
    "    clf_linear = svm.SVC(kernel='linear',C=0.095)\n",
    "    clf_linear.fit(X_trainA,Y_trainA)\n",
    "    score_linear_test = clf_linear.score(X_testA,Y_testA)\n",
    "    score_linear_train = clf_linear.score(X_trainA,Y_trainA)\n",
    "    predict_test = clf_linear.predict(X_testA)\n",
    "    print(predict_test,Y_testA)\n",
    "    print(epoch,\"SVM Test  Accuracy : %.4g\" % (score_linear_test))\n",
    "    print(epoch,\"SVM Train  Accuracy : %.4g\" % (score_linear_train))\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizerPE.step()\n",
    "    optimizerNE.step()\n",
    "    optimizerPT.step()\n",
    "    optimizerNE.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Total Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729aa5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21736627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part3 Att_crm\n",
    "from math import sqrt\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "class Att_cross(nn.Module):\n",
    "    def __init__(self, modelsC, device='cpu'):\n",
    "        super(Att_cross, self).__init__()\n",
    "        \n",
    "        self.modelsC = modelsC \n",
    " \n",
    "    def forward(self):\n",
    "\n",
    "        X_newRA_IIIA = torch.tensor(X_newRA_III, dtype=torch.float64)\n",
    "        X_newEA_IIIA = torch.tensor(X_newEA_III, dtype=torch.float64)\n",
    "        \n",
    "        Feature3=torch.zeros((iii+7,161),dtype=torch.float64)\n",
    "        \n",
    "        for i in range(iii+7):\n",
    "            u,v=0,0;\n",
    "            for j in range(161):\n",
    "                if (j%7==op_now):\n",
    "                    Feature3[i][j]=to_tensor(X_newEA_IIIA[u][i])\n",
    "                    u=u+1\n",
    "                else:\n",
    "                    Feature3[i][j]=to_tensor(X_newRA_IIIA[v][i])\n",
    "                    v=v+1\n",
    "        YQ1=self.modelsC(Feature3)\n",
    "        tagAA3=torch.sum(YQ1, dim=1)\n",
    "    \n",
    "        u,v=0,0;\n",
    "        for i in range(161):\n",
    "            if (i%7==op_now):\n",
    "                for j in range(iii+7):\n",
    "                    X_newEA_IIIA[u][j]=X_newEA_IIIA[u][j].clone()*tagAA3[j]\n",
    "                u=u+1\n",
    "            else:\n",
    "                for j in range(iii+7):\n",
    "                    X_newRA_IIIA[v][j]=X_newRA_IIIA[v][j].clone()*tagAA3[j]\n",
    "                v=v+1\n",
    "        \n",
    "        return X_newRA_IIIA,X_newEA_IIIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4799598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=SelfAttention(161, iii+7, iii+7, device='cpu')\n",
    "save_model = torch.load(\"./ARZE\"+str(iii)+\"P\"+str(op_now)+\".pth\")\n",
    "model_dict = model3.state_dict()\n",
    "state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "model_dict.update(state_dict)\n",
    "model3.load_state_dict(model_dict)\n",
    "print(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_cross = Att_cross(modelsC=model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a795f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(att_cross.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tensor=torch.from_numpy(Y_train)\n",
    "Y_train_tensor=Y_train_tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    att_cross.train()\n",
    "\n",
    "    outputR,outputE = att_cross()\n",
    "        \n",
    "    loss = criterion(outputR,Y_train_tensor)\n",
    "    \n",
    "    print(outputR,outputE)\n",
    "        \n",
    "    X_trainA=outputR.detach().numpy()\n",
    "    Y_trainA=Y_train\n",
    "    X_testA=outputE.detach().numpy()\n",
    "    Y_testA=Y_test\n",
    "    print(X_trainA.shape)\n",
    "    print(X_testA.shape)\n",
    "    clf_linear = svm.SVC(kernel='linear',C=0.095)\n",
    "    clf_linear.fit(X_trainA,Y_trainA)\n",
    "    score_linear_test = clf_linear.score(X_testA,Y_testA)\n",
    "    score_linear_train = clf_linear.score(X_trainA,Y_trainA)\n",
    "    predict_test = clf_linear.predict(X_testA)\n",
    "    print(predict_test,Y_testA)\n",
    "    print(epoch,\"SVM Test  Accuracy : %.4g\" % (score_linear_test))\n",
    "    print(epoch,\"SVM Train  Accuracy : %.4g\" % (score_linear_train))\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Total Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
