{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7abe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "import scipy.io as scio\n",
    "data={ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a079595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genomics and clinical neurodiagnostic scale records were imported\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./ADNI_MUL_T1_6_24_2024.csv\",encoding=\"ANSI\")\n",
    "df_array = np.array(df)\n",
    "df_list = df_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction\n",
    "tA,tB,tC,tD=0,0,0,0\n",
    "X_2dA = [[0 for i in range(8)]for j in range(29)]\n",
    "Y_2dA =[0 for i in range(29)]\n",
    "X_2dB = [[0 for i in range(8)]for j in range(49)]\n",
    "Y_2dB =[0 for i in range(49)]\n",
    "X_2dC = [[0 for i in range(8)]for j in range(51)]\n",
    "Y_2dC =[0 for i in range(51)]\n",
    "X_2dD = [[0 for i in range(8)]for j in range(32)]\n",
    "Y_2dD =[0 for i in range(32)]\n",
    "for i in range(1,161):\n",
    "    if df_list[i][4]=='1':\n",
    "        X_2dA[tA][0]=np.array(df_list[i][20])\n",
    "        X_2dA[tA][1]=np.array(df_list[i][22])\n",
    "        X_2dA[tA][2]=np.array(df_list[i][24])\n",
    "        X_2dA[tA][3]=np.array(df_list[i][26])\n",
    "        X_2dA[tA][4]=np.array(df_list[i][28])\n",
    "        X_2dA[tA][5]=np.array(df_list[i][29])\n",
    "        X_2dA[tA][6]=np.array(df_list[i][30])\n",
    "        X_2dA[tA][7]=np.array(df_list[i][19])\n",
    "        Y_2dA[tA]=np.array(df_list[i][4])\n",
    "        tA=tA+1\n",
    "for i in range(1,161):\n",
    "    if df_list[i][4]=='2':\n",
    "        X_2dB[tB][0]=np.array(df_list[i][20])\n",
    "        X_2dB[tB][1]=np.array(df_list[i][22])\n",
    "        X_2dB[tB][2]=np.array(df_list[i][24])\n",
    "        X_2dB[tB][3]=np.array(df_list[i][26])\n",
    "        X_2dB[tB][4]=np.array(df_list[i][28])\n",
    "        X_2dB[tB][5]=np.array(df_list[i][29])\n",
    "        X_2dB[tB][6]=np.array(df_list[i][30])\n",
    "        X_2dB[tB][7]=np.array(df_list[i][19])\n",
    "        Y_2dB[tB]=np.array(df_list[i][4])\n",
    "        tB=tB+1\n",
    "for i in range(1,161):\n",
    "    if df_list[i][4]=='3':\n",
    "        X_2dC[tC][0]=np.array(df_list[i][20])\n",
    "        X_2dC[tC][1]=np.array(df_list[i][22])\n",
    "        X_2dC[tC][2]=np.array(df_list[i][24])\n",
    "        X_2dC[tC][3]=np.array(df_list[i][26])\n",
    "        X_2dC[tC][4]=np.array(df_list[i][28])\n",
    "        X_2dC[tC][5]=np.array(df_list[i][29])\n",
    "        X_2dC[tC][6]=np.array(df_list[i][30])\n",
    "        X_2dC[tC][7]=np.array(df_list[i][19])\n",
    "        Y_2dC[tC]=np.array(df_list[i][4])\n",
    "        tC=tC+1\n",
    "for i in range(1,161):\n",
    "    if df_list[i][4]=='4':\n",
    "        X_2dD[tD][0]=np.array(df_list[i][20])\n",
    "        X_2dD[tD][1]=np.array(df_list[i][22])\n",
    "        X_2dD[tD][2]=np.array(df_list[i][24])\n",
    "        X_2dD[tD][3]=np.array(df_list[i][26])\n",
    "        X_2dD[tD][4]=np.array(df_list[i][28])\n",
    "        X_2dD[tD][5]=np.array(df_list[i][29])\n",
    "        X_2dD[tD][6]=np.array(df_list[i][30])\n",
    "        X_2dD[tD][7]=np.array(df_list[i][19])\n",
    "        Y_2dD[tD]=np.array(df_list[i][4])\n",
    "        tD=tD+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_2d =[0 for i in range(161)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6292a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "It=0\n",
    "for i in range(120):\n",
    "    if i==0 or i==3 or i==4 or i==6 or i==42 or i==84 or i==114:\n",
    "        continue\n",
    "    Y_2d[It]=df_list[i][4]\n",
    "    print(Y_2d[It])\n",
    "    It=It+1\n",
    "print(It)\n",
    "for i in range(51):\n",
    "    if i==0 or i==31 or i==32:\n",
    "        continue;\n",
    "    Y_2d[It]=df_listA[i][4]\n",
    "    print(np.array(Y_2d[It]))\n",
    "    It=It+1\n",
    "print(It)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data imputation ：Imputation is carried out according to the classification of different pathological processes\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "imputer = KNNImputer(n_neighbors=15)\n",
    "X_2dA=imputer.fit_transform(X_2dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "imputer = KNNImputer(n_neighbors=25)\n",
    "X_2dB=imputer.fit_transform(X_2dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "imputer = KNNImputer(n_neighbors=26)\n",
    "X_2dC=imputer.fit_transform(X_2dC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "imputer = KNNImputer(n_neighbors=18)\n",
    "X_2dD=imputer.fit_transform(X_2dD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623000c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data integration\n",
    "tAA,tBB,tCC,tDD=0,0,0,0\n",
    "X_2d = [[0 for i in range(8)]for j in range(161)]\n",
    "Y_2d =[0 for i in range(161)]\n",
    "t=0\n",
    "for i in range(1,161):\n",
    "    if np.array(df_list[i][4])=='0':\n",
    "        continue;\n",
    "    if np.array(df_list[i][4])=='1':\n",
    "        X_2d[t]=np.array(X_2dA[tAA])\n",
    "        Y_2d[t]=np.array(Y_2dA[tAA])\n",
    "        tAA=tAA+1\n",
    "        t=t+1\n",
    "    if np.array(df_list[i][4])=='2':\n",
    "        X_2d[t]=np.array(X_2dB[tBB])\n",
    "        Y_2d[t]=np.array(Y_2dB[tBB])\n",
    "        tBB=tBB+1\n",
    "        t=t+1\n",
    "    if np.array(df_list[i][4])=='3':\n",
    "        X_2d[t]=np.array(X_2dC[tCC])\n",
    "        Y_2d[t]=np.array(Y_2dC[tCC])\n",
    "        tCC=tCC+1\n",
    "        t=t+1\n",
    "    if np.array(df_list[i][4])=='4':\n",
    "        X_2d[t]=np.array(X_2dD[tDD])\n",
    "        Y_2d[t]=np.array(Y_2dD[tDD])\n",
    "        tDD=tDD+1\n",
    "        t=t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "YY=np.array(Y_2d,dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression,f_classif\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim_q, dim_k, dim_v, device='cpu'):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "        self.device=device\n",
    "\n",
    "        self.linear_q = nn.Linear(dim_q, dim_k, bias=False).to(self.device)\n",
    "        self.linear_k = nn.Linear(dim_q, dim_k, bias=False).to(self.device)\n",
    "        self.linear_v = nn.Linear(dim_q, dim_v, bias=False).to(self.device)\n",
    "        self._norm_fact = 1 / sqrt(dim_k)\n",
    " \n",
    "    def forward(self, x):\n",
    "        batch, dim_q = x.shape\n",
    "        n = 1\n",
    "        assert dim_q == self.dim_q\n",
    "        x =x.to(self.device)\n",
    "        q = self.linear_q(x)\n",
    "        k = self.linear_k(x)\n",
    "        v = self.linear_v(x)\n",
    "        \n",
    "        dist = torch.matmul(q, k.transpose(0, 1)) * self._norm_fact\n",
    "        dist = torch.softmax(dist, dim=-1)\n",
    "        att = torch.matmul(dist, v)\n",
    "        return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6735ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC=np.array([0 for i in range(1000)],dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "XXD=np.array(XXX_2d)\n",
    "YYD=np.array(Y_2d)\n",
    "XXD=pd.DataFrame(XXD)\n",
    "print(XXD.columns[0])\n",
    "print(XX)\n",
    "print(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the results of brain network segmentation\n",
    "import pandas as pd\n",
    "file_ROI = './ROI.xlsx'\n",
    "SE_ROI = pd.read_excel(file_ROI,sheet_name = 'Sheet1')\n",
    "se_roi = np.array(SE_ROI)\n",
    "se_roi_list = se_roi.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DJPOS:\n",
    "    def __init__(self):\n",
    "        self.feature=0\n",
    "        self.pos=0\n",
    "        self.pos_ac=0\n",
    "\n",
    "def cmp(a, b):\n",
    "    if a.feature < b.feature: \n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def cmpA(a,b):\n",
    "    if a.pos<b.pos:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a037c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from functools import cmp_to_key\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "from shutil import copyfile\n",
    "Best_ACC=0\n",
    "Best_RE=0\n",
    "Best_F1=0\n",
    "Best_FLAG=0\n",
    "LOW_ACC=1.1\n",
    "LOW_RE=1.1\n",
    "LOW_F1=1.1\n",
    "LOW_FLAG=0\n",
    "AVG_ACC=0\n",
    "DF=0;\n",
    "DB=0;\n",
    "DV=0;\n",
    "DM=0;\n",
    "ACC_ALL=0;\n",
    "op_now=1\n",
    "ACCNOW = [0 for j in range(825)]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device ='cpu'\n",
    "\n",
    "\n",
    "ROI_record = [[0 for j in range(825)] for i in range(8)]\n",
    "X_bian_R = np.array([[[0 for j in range(161)] for i in range(825)] for k in range(8)],dtype='float')\n",
    "NUM_R = [0 for i in range(8)]\n",
    "NA = np.array([0 for i in range (825)],dtype='float')\n",
    "\n",
    "\n",
    "PARA1=np.array([0 for i in range(1024)],dtype='float')\n",
    "PARA2=np.array([0 for i in range(1024)],dtype='float')\n",
    "PARA3=np.array([0 for i in range(1024)],dtype='float')\n",
    "\n",
    "JB=0\n",
    "fl=45\n",
    "for iii in range(50,250):\n",
    "    # I.Graph Structure Modeling module\n",
    "    selector = SelectKBest(f_classif, k=iii)\n",
    "    data=scio.loadmat('./floyd'+str(100-fl)+'_'+str(fl)+'.mat')\n",
    "    X ={ }\n",
    "    data_C ={ }\n",
    "    data_W ={ }\n",
    "    XXX_2d = [[0 for i in range(13858)]for j in range(161)]\n",
    "    for i in range(161):\n",
    "        X[i]=data['Z'][i]\n",
    "\n",
    "    t=0\n",
    "    for i in range(1,162):\n",
    "        data_C[i]=scio.loadmat('./floyd'+str(100-fl)+'_'+str(fl)+'_'+str(i)+'.mat')\n",
    "    data_W=scio.loadmat('./floyd'+str(100-fl)+'_'+str(fl)+'.mat')\n",
    "    data_CC=np.array([[0 for i in range(164)]for j in range(161)],dtype='float')\n",
    "    data_LL=np.array([0 for i in range(161)],dtype='float')\n",
    "    data_WW=np.array([0 for i in range(161)],dtype='float')\n",
    "    for i in range(1,162):\n",
    "        for j in range(164):\n",
    "            data_CC[i-1][j]=np.array(data_C[i]['C'][j],dtype='float')\n",
    "    for i in range(161):\n",
    "        data_WW[i]=np.array(data_W['Smallworld'][0][i],dtype='float')\n",
    "    for i in range(161):\n",
    "        t=0\n",
    "        for k in range(0,164):\n",
    "            for l in range(k+1,164):\n",
    "                XXX_2d[i][t]=np.array(X[i][k,l])\n",
    "                t=t+1\n",
    "        for k in range(0,164):\n",
    "            for l in range(164,167):\n",
    "                if (l==164):\n",
    "                    XXX_2d[i][t]=np.array(X[i][k,l])*data_CC[i][k]*data_WW[i]\n",
    "                else:\n",
    "                    XXX_2d[i][t]=np.array(X[i][k,l])\n",
    "                t=t+1\n",
    "\n",
    "    XX=np.array(XXX_2d,dtype='float')\n",
    "    X_train =np.array([[0 for i in range(13858)] for j in range(138)],dtype='float')\n",
    "    X_test =np.array([[0 for i in range(13858)] for j in range(23)],dtype='float')\n",
    "    Y_train=np.array([0 for i in range(138)],dtype='int')\n",
    "    Y_test=np.array([0 for i in range(23)],dtype='int')\n",
    "    X_trainA =np.array([[0 for i in range(iii+7)] for j in range(138)],dtype='float')\n",
    "    X_testA =np.array([[0 for i in range(iii+7)] for j in range(23)],dtype='float')\n",
    "    Y_trainA=np.array([0 for i in range(138)],dtype='int')\n",
    "    Y_testA=np.array([0 for i in range(23)],dtype='int')\n",
    "    \n",
    "    POS_record_train = [[0 for i in range(825)] for j in range(138)]\n",
    "    NEV_record_train = [[0 for j in range(825)] for i in range(138)]\n",
    "    X_bian_P_train = np.array([[0 for j in range(138)] for i in range(825)],dtype='float')\n",
    "    X_bian_N_train = np.array([[0 for j in range(138)] for i in range(825)],dtype='float')\n",
    "    POS_train = [0 for i in range(138)]\n",
    "    NEV_train = [0 for i in range(138)]\n",
    "    \n",
    "    POS_record_test = [[0 for i in range(825)] for j in range(23)]\n",
    "    NEV_record_test = [[0 for j in range(825)] for i in range(23)]\n",
    "    X_bian_P_test = np.array([[0 for j in range(23)] for i in range(825)],dtype='float')\n",
    "    X_bian_N_test = np.array([[0 for j in range(23)] for i in range(825)],dtype='float')\n",
    "    POS_test = [0 for i in range(23)]\n",
    "    NEV_test = [0 for i in range(23)]\n",
    "    \n",
    "    u,v=0,0;\n",
    "    for j in range(161):\n",
    "        if (j%7==op_now):\n",
    "            X_test[u]=XX[j]\n",
    "            Y_test[u]=YY[j]\n",
    "            u=u+1;\n",
    "        else:\n",
    "            X_train[v]=XX[j]\n",
    "            Y_train[v]=YY[j]\n",
    "            v=v+1;\n",
    "    X_newR = selector.fit_transform(X_train,Y_train)\n",
    "    X_newE = selector.transform(X_test)\n",
    "    scores = selector.scores_\n",
    "    p_values = selector.pvalues_\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    k_best_features = list(XXD.columns.values[indices[0:iii]])\n",
    "    list_BEST= []\n",
    "    for ii in range(iii):\n",
    "        list_BEST.append(DJPOS())\n",
    "        list_BEST[ii].feature=k_best_features[ii]\n",
    "        list_BEST[ii].pos=ii\n",
    "\n",
    "    list_BEST.sort(key=cmp_to_key(cmp))\n",
    "\n",
    "    for ii in range(iii):\n",
    "        list_BEST[ii].pos_ac=ii\n",
    "    \n",
    "    list_BEST.sort(key=cmp_to_key(cmpA))\n",
    "    \n",
    "    for ii in range(JB,iii):\n",
    "        t=0\n",
    "        for k in range(0,164):\n",
    "            if (t>k_best_features[ii]):\n",
    "                break\n",
    "            for l in range(k+1,164):\n",
    "                FLAG_LI=np.array([0 for i in range(8)])\n",
    "                if t==k_best_features[ii]:\n",
    "                    X1 = XX[:,k_best_features[ii]]\n",
    "                    for TTT in range(2,6):\n",
    "                        Rnow=np.array(se_roi[k][TTT],dtype='int')-1\n",
    "                        if FLAG_LI[Rnow]==0:\n",
    "                            X_bian_R[Rnow][NUM_R[Rnow]]=X1.reshape(1,-1)\n",
    "                            ROI_record[Rnow][NUM_R[Rnow]]=ii\n",
    "                            FLAG_LI[Rnow]=1\n",
    "                            NUM_R[Rnow]=NUM_R[Rnow]+1\n",
    "                            NA[ii]=NA[ii]+1\n",
    "                        if (np.isnan(se_roi[k][TTT+1])):\n",
    "                            break\n",
    "                    for TTT in range(2,6):\n",
    "                        Rnow=np.array(se_roi[l][TTT],dtype='int')-1\n",
    "                        if FLAG_LI[Rnow]==0:\n",
    "                            X_bian_R[Rnow][NUM_R[Rnow]]=X1.reshape(1,-1)\n",
    "                            ROI_record[Rnow][NUM_R[Rnow]]=ii\n",
    "                            FLAG_LI[Rnow]=1\n",
    "                            NUM_R[Rnow]=NUM_R[Rnow]+1\n",
    "                            NA[ii]=NA[ii]+1\n",
    "                        if (np.isnan(se_roi[l][TTT+1])):\n",
    "                            break\n",
    "                t=t+1\n",
    "                if (t>k_best_features[ii]):\n",
    "                    break\n",
    "        JB=ii+1\n",
    "    \n",
    "    \n",
    "    for jb in range(0,iii):\n",
    "        for ja in range(138):\n",
    "            if (X_newR[ja][jb]>0):\n",
    "                POS_record_train[ja][POS_train[ja]]=jb\n",
    "                X_bian_P_train[POS_train[ja]][ja]=np.array(X_newR[ja][jb],dtype='float')\n",
    "                POS_train[ja]=POS_train[ja]+1\n",
    "            if (X_newR[ja][jb]<0):\n",
    "                NEV_record_train[ja][NEV_train[ja]]=jb\n",
    "                X_bian_N_train[NEV_train[ja]][ja]=np.array(X_newR[ja][jb],dtype='float')\n",
    "                NEV_train[ja]=NEV_train[ja]+1\n",
    "    \n",
    "    for jb in range(0,iii):\n",
    "        for ja in range(23):\n",
    "            if (X_newE[ja][jb]>0):\n",
    "                POS_record_test[ja][POS_test[ja]]=jb\n",
    "                X_bian_P_test[POS_test[ja]][ja]=np.array(X_newE[ja][jb],dtype='float')\n",
    "                POS_test[ja]=POS_test[ja]+1\n",
    "            if (X_newE[ja][jb]<0):\n",
    "                NEV_record_test[ja][NEV_test[ja]]=jb\n",
    "                X_bian_N_test[NEV_test[ja]][ja]=np.array(X_newE[ja][jb],dtype='float')\n",
    "                NEV_test[ja]=NEV_test[ja]+1\n",
    "    \n",
    "    X_newRA_I = np.array([[0 for i in range(iii+7)] for j in range(138)],dtype='float')\n",
    "    X_newEA_I = np.array([[0 for i in range(iii+7)] for j in range(23)],dtype='float')\n",
    "    \n",
    "    X_newRA_II = np.array([[0 for i in range(iii+7)] for j in range(138)],dtype='float')\n",
    "    X_newEA_II = np.array([[0 for i in range(iii+7)] for j in range(23)],dtype='float')\n",
    "    \n",
    "    X_newRA_III = np.array([[0 for i in range(iii+7)] for j in range(138)],dtype='float')\n",
    "    X_newEA_III = np.array([[0 for i in range(iii+7)] for j in range(23)],dtype='float')\n",
    "    \n",
    "    Feature=np.zeros((iii+7,161))\n",
    "    u,v=0,0;\n",
    "\n",
    "    for i in range(161):\n",
    "        if (i%7==op_now):\n",
    "            for j in range(iii):\n",
    "                X_newEA_I[u][j]=X_newE[u][j]\n",
    "                X_newEA_II[u][j]=X_newE[u][j]\n",
    "                X_newEA_III[u][j]=X_newE[u][j]\n",
    "            t=iii\n",
    "            for j in range(7):\n",
    "                X_newEA_I[u][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                X_newEA_II[u][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                X_newEA_III[u][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                t=t+1\n",
    "            u=u+1\n",
    "        else:\n",
    "            for j in range(iii):\n",
    "                X_newRA_I[v][j]=X_newR[v][j]\n",
    "                X_newRA_II[v][j]=X_newR[v][j]\n",
    "                X_newRA_III[v][j]=X_newR[v][j]\n",
    "            t=iii\n",
    "            for j in range(7):\n",
    "                X_newRA_I[v][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                X_newRA_II[v][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                X_newRA_III[v][t]=np.array(X_2d[i][j],dtype=float)\n",
    "                t=t+1\n",
    "            v=v+1\n",
    "        \n",
    "    u,v=0,0\n",
    "    \n",
    "    X_newRO = np.array(X_newRA_I)\n",
    "    X_newEO = np.array(X_newEA_I)\n",
    "    \n",
    "    #.IIA：Att_net\n",
    "    for lll in range(8):\n",
    "        if (NUM_R[lll]!=0):\n",
    "            model=SelfAttention(161,NUM_R[lll],NUM_R[lll])\n",
    "            save_model = torch.load(\"./SA_FINAL_\"+str(op_now)+\"_\"+str(iii)+\"_\"+str(lll)+\".pth\")\n",
    "            model_dict =  model.state_dict()\n",
    "            state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "            model_dict.update(state_dict)\n",
    "            Feature=np.zeros((NUM_R[lll],161))\n",
    "            model.load_state_dict(model_dict)\n",
    "            for i in range(161):\n",
    "                for j in range(NUM_R[lll]):   \n",
    "                    Feature[j][i]=np.array(X_bian_R[lll][j][i])\n",
    "            Feature_tensor = torch.from_numpy(Feature)\n",
    "            YQ=model(Feature_tensor)\n",
    "            tagAA=torch.sum(YQ,dim=1).cpu().detach().numpy().reshape(-1, 1)        \n",
    "            tagAAG = scaler.fit_transform(tagAA)\n",
    "            tagAAG=tagAAG.reshape(-1, 1)\n",
    "            for j in range(NUM_R[lll]):\n",
    "                SS1 = np.array(ROI_record[lll][j],dtype='int')\n",
    "                SS2 = np.array(list_BEST[SS1].pos_ac,dtype='int')\n",
    "            X_newRA_I[:,SS2]=X_newRA_I[:,SS2]+np.array(X_newR[:,SS2]*(tagAAG[j]/NA[SS1]),dtype='float')\n",
    "            X_newEA_I[:,SS2]=X_newEA_I[:,SS2]+np.array(X_newE[:,SS2]*(tagAAG[j]/NA[SS1]),dtype='float')\n",
    "\n",
    "    #IIB. Att_pnw\n",
    "    u,v=0,0\n",
    "    for lll in range(161):\n",
    "        if (lll%7==op_now):\n",
    "            tagAA1=torch.zeros(POS_test[u])\n",
    "            tagAA2=torch.zeros(NEV_test[u])\n",
    "            if (POS_test[u]!=0):\n",
    "                model1=SelfAttention(1,POS_test[u],POS_test[u])\n",
    "                save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll)+\"_\"+str(op_now)+\"A.pth\")\n",
    "                model_dict =  model1.state_dict()\n",
    "                state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "                model_dict.update(state_dict)\n",
    "                model1.load_state_dict(model_dict)\n",
    "                Feature1=np.zeros((POS_test[u],1))\n",
    "                for j in range(POS_test[u]):\n",
    "                    Feature1[j][0]=np.array(X_bian_P_test[j][u])\n",
    "                Feature_tensor = torch.from_numpy(Feature1)\n",
    "                YQ1=model1(Feature_tensor)\n",
    "                tagAA1=torch.sum(YQ1,dim=1)\n",
    "                for j in range(POS_test[u]): \n",
    "                    X_newEA_II[u][POS_record_test[u][j]]=X_newEA_II[u][POS_record_test[u][j]]*(tagAA1[j].cpu().detach().numpy())\n",
    "            if (NEV_test[u]!=0):\n",
    "                model2=SelfAttention(1,NEV_test[u],NEV_test[u])\n",
    "                save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll)+\"_\"+str(op_now)+\"B.pth\")\n",
    "                model_dict =  model1.state_dict()\n",
    "                state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "                model_dict.update(state_dict)\n",
    "                model2.load_state_dict(model_dict)\n",
    "                Feature2=np.zeros((NEV_test[u],1))\n",
    "                for j in range(NEV_test[u]):\n",
    "                    Feature2[j][0]=np.array(X_bian_N_test[j][u])\n",
    "                Feature_tensor = torch.from_numpy(Feature2)\n",
    "                YQ2=model2(Feature_tensor)\n",
    "                tagAA2=torch.sum(YQ2,dim=1)\n",
    "                for j in range(NEV_test[u]):\n",
    "                    X_newEA_II[u][NEV_record_test[u][j]]=X_newEA_II[u][NEV_record_test[u][j]]*(tagAA2[j].cpu().detach().numpy())\n",
    "            u=u+1\n",
    "        else:\n",
    "            tagAA1=torch.zeros(POS_train[v])\n",
    "            tagAA2=torch.zeros(NEV_train[v])\n",
    "            if (POS_train[v]!=0):\n",
    "                model1=SelfAttention(1,POS_train[v],POS_train[v])\n",
    "                save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll)+\"_\"+str(op_now)+\"A.pth\")\n",
    "                model_dict =  model1.state_dict()\n",
    "                state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "                model_dict.update(state_dict)\n",
    "                model1.load_state_dict(model_dict)\n",
    "                Feature1=np.zeros((POS_train[v],1))\n",
    "                for j in range(POS_train[v]):\n",
    "                    Feature1[j][0]=np.array(X_bian_P_train[j][v])\n",
    "                Feature_tensor = torch.from_numpy(Feature1)\n",
    "                YQ1=model1(Feature_tensor)\n",
    "                tagAA1=torch.sum(YQ1,dim=1)\n",
    "                for j in range(POS_train[v]): \n",
    "                    X_newRA_II[v][POS_record_train[v][j]]=X_newRA_II[v][POS_record_train[v][j]]*(tagAA1[j].cpu().detach().numpy())\n",
    "            if (NEV_train[v]!=0):\n",
    "                model2=SelfAttention(1,NEV_train[v],NEV_train[v])\n",
    "                save_model = torch.load(\"./SA_FINAL_\"+str(iii)+\"_\"+str(lll)+\"_\"+str(op_now)+\"B.pth\")\n",
    "                model_dict =  model1.state_dict()\n",
    "                state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "                model_dict.update(state_dict)\n",
    "                model2.load_state_dict(model_dict)\n",
    "                Feature2=np.zeros((NEV_train[v],1))\n",
    "                for j in range(NEV_train[v]):\n",
    "                    Feature2[j][0]=np.array(X_bian_N_train[j][v])\n",
    "                Feature_tensor = torch.from_numpy(Feature2)\n",
    "                YQ2=model2(Feature_tensor)\n",
    "                tagAA2=torch.sum(YQ2,dim=1)\n",
    "                for j in range(NEV_train[v]):\n",
    "                    X_newRA_II[v][NEV_record_train[v][j]]=X_newRA_II[v][NEV_record_train[v][j]]*(tagAA2[j].cpu().detach().numpy())\n",
    "            v=v+1\n",
    "    \n",
    "    # IIC. Att_crm\n",
    "    model=SelfAttention(161,iii+7,iii+7)\n",
    "    Feature=np.zeros((iii+7,161))\n",
    "    save_model = torch.load(\"./ARZE\"+str(iii)+\"P\"+str(op_now)+\".pth\")\n",
    "    model_dict =  model.state_dict()\n",
    "    state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    for i in range(iii+7):\n",
    "        u,v=0,0;\n",
    "        for j in range(161):\n",
    "            if (j%7==op_now):\n",
    "                Feature[i][j]=np.array(X_newEA_III[u][i])\n",
    "                u=u+1\n",
    "            else:\n",
    "                Feature[i][j]=np.array(X_newRA_III[v][i])\n",
    "                v=v+1\n",
    "    Feature_tensor = torch.from_numpy(Feature)\n",
    "    YQ1=model(Feature_tensor)\n",
    "    tagAA3=torch.sum(YQ1, dim=1)\n",
    "    \n",
    "    u,v=0,0;\n",
    "    for i in range(161):\n",
    "        if (i%7==op_now):\n",
    "            for j in range(iii+7):\n",
    "                X_newEA_III[u][j]=X_newEA_III[u][j]*tagAA3[j].detach().numpy()\n",
    "            u=u+1\n",
    "        else:\n",
    "            for j in range(iii+7):\n",
    "                X_newRA_III[v][j]=X_newRA_III[v][j]*tagAA3[j].detach().numpy()\n",
    "            v=v+1\n",
    "    u,v=0,0;\n",
    "    \n",
    "    X_newEA_II = scaler.fit_transform(X_newEA_II)\n",
    "    X_newRA_II = scaler.fit_transform(X_newRA_II)\n",
    "    \n",
    "    \n",
    "    #III :Fusion\n",
    "    for para1 in range(0,100):\n",
    "        for para2 in range(0,100-para1):\n",
    "            para3=100-para1-para2\n",
    "            pa1=np.array(para1/100,dtype='float')\n",
    "            pa2=np.array(para2/100,dtype='float')\n",
    "            pa3=np.array(para3/100,dtype='float')\n",
    "            \n",
    "            X_newRV=X_newRA_I*pa1+X_newRA_II*pa2+X_newRA_III*pa3\n",
    "            X_newEV=X_newEA_I*pa1+X_newEA_II*pa2+X_newEA_III*pa3\n",
    "            \n",
    "            X_newRV = scaler.fit_transform(X_newRV)\n",
    "            X_newEV = scaler.fit_transform(X_newEV)\n",
    "            \n",
    "            ACC=0;\n",
    "            cnt=0;\n",
    "            u,v=0,0\n",
    "            for j in range(161):\n",
    "                if (j%7==op_now):\n",
    "                    X_testA[u]=X_newEV[u]\n",
    "                    Y_testA[u]=YY[j]\n",
    "                    u=u+1;\n",
    "                else:\n",
    "                    X_trainA[v]=X_newRV[v]\n",
    "                    Y_trainA[v]=YY[j]\n",
    "                    v=v+1;\n",
    "#             print(X_train,Y_train)\n",
    "            clf_linear = svm.SVC(kernel='linear',C=0.095)\n",
    "            clf_linear.fit(X_trainA,Y_trainA)\n",
    "            score_linear_test = clf_linear.score(X_testA,Y_testA)\n",
    "            score_linear_train = clf_linear.score(X_trainA,Y_trainA)\n",
    "            predict_test = clf_linear.predict(X_testA)\n",
    "#         print(\"SVM Test  Accuracy : %.4g\" % (score_linear_test))\n",
    "#         print(\"SVM Train  Accuracy : %.4g\" % (score_linear_train))\n",
    "            ACC=ACC+score_linear_test;\n",
    "            cnt=cnt+1;\n",
    "            ACC=ACC/cnt\n",
    "            AVG_ACC=AVG_ACC+ACC\n",
    "            if ACC>Best_ACC:\n",
    "                Best_FLAG=iii\n",
    "                Best_ACC=ACC\n",
    "            if ACC<LOW_ACC:\n",
    "                LOW_FLAG=iii\n",
    "                LOW_ACC=ACC\n",
    "            with open('./IAA-combine_1A.txt', 'a') as f:\n",
    "                f.write(f\"iii: {iii} para1: {para1} para2: {para2} para3: {para3} ACC: {ACC}\\n\")\n",
    "            if (ACCNOW[iii]<ACC):\n",
    "                ACCNOW[iii]=ACC\n",
    "                PARA1[iii]=para1\n",
    "                PARA2[iii]=para2\n",
    "                PARA3[iii]=para3\n",
    "            if (ACC_ALL<ACC):\n",
    "                ACC_ALL=ACC\n",
    "    print(\"iii:\",iii,\" para1:\",PARA1[iii],\" para2:\",PARA2[iii],\" para3:\",PARA3[iii],\" ACC:\",ACCNOW[iii])\n",
    "print(\"BEST:\")\n",
    "print(Best_FLAG,Best_ACC)\n",
    "print(LOW_FLAG,LOW_ACC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
